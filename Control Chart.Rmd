---
title: "R Notebook"
output: PDF
---
# Library

```{r, message = FALSE}
library(fda)
library(purrr)
library(gmfd)
library(roahd)
library(doSNOW)
library(pracma)
library(fdapace)
library(foreach)
library(fda.usc)
library(ggplot2)
library(gStream)
library(reshape2)
library(parallel)
library(doParallel)
library(fdaoutlier)
```

# Simulate functional data

```{r}
# under different ARL settings, whether methods have similar performance differences
# why after performing FPCA does worse
t_values <- seq(0, 1, length.out = 1000)
N <- 200    # 這是要模擬的功能實現的數量
L <- 150    # 基擴展中的項數
sim1 <- function(rho = 0, mean_change=TRUE, scale, cov_change=FALSE){
  
  phi <- function(l, t) {
    if (l == 0) {
      return(1)
    } else if (l %% 2 == 1) {
      k <- (l + 1) / 2
      return(sqrt(2) * sin(2 * pi * k * t - pi))
    } else {
      k <- l / 2
      return(sqrt(2) * cos(2 * pi * k * t - pi))
    }
  }
  
  # plot(t_values, phi(1, t_values), type = "l", xlab = "t", ylab = "phi(150, t)")
  # for(i in 2:20) {
  #   lines(t_values, phi(i, t_values), col = "red")
  # }
  
  lambda <- function(l) {
    return(0.7 * 2^(-l))
  }
  generate_tau <- function(N, L, rho, scale, cov_change) {
    tau <- matrix(0, N, L + 1)
    for (i in 1:N) {
      for (l in 1:(L + 1)) {
        if (i == 1) {
          tau[i,l] <- rnorm(1)
        }
        else if (i <= 150){ # 3/4 * N
          tau[i,l] <- rho * tau[i - 1, l] + rnorm(1)
        }
        else{
          tau[i,l] <- rho * tau[i - 1, l] + scale * ifelse(cov_change, rexp(1), rnorm(1))
        }
      }
    }
    return(tau)
  }
  
  mean_function <- function(t, i, N) {
    if(mean_change == TRUE){
      if (i <= 150) { # 3/4 * N
        return(0.5 - 100 * (t - 0.1) * (t - 0.3) * (t - 0.5) * (t - 0.9) + 0.8 * sin(1+10*pi*t))
      } else{
        return(1 + 3*t^2 - 5*t^3)
      }
    }
    else{
      return(0.5 - 100 * (t - 0.1) * (t - 0.3) * (t - 0.5) * (t - 0.9) + 0.8 * sin(1+10*pi*t))
    }
  }
  # scale_function <- function(t, i, N) {
  #   if (i <= 3/4 * N) {
  #     return(t)
  #   } else {
  #     return(2*t)
  #   }
  # }
  simulate_Y <- function(N, L, rho, t_values) {
    Phi <- sapply(0:L, function(l) sapply(t_values, function(t) phi(l, t)))
    Lambda <- diag(sapply(0:L, function(l) sqrt(lambda(l))))
    Tau_scaled <- generate_tau(N, L, rho, scale, cov_change) %*% t(Lambda)
    MeanVals <- matrix(nrow = N, ncol = length(t_values))
    for (i in 1:N) {
      for (t_index in 1:length(t_values)) {
        MeanVals[i, t_index] <- mean_function(t_values[t_index], i, N)
      }
    }
    Y <- MeanVals + Tau_scaled %*% t(Phi)
    return(Y)
    
    # tau <- generate_tau(N, L, rho, scale)
    # Y <- matrix(0, N, length(t_values))
    # for (i in 1:N) {
    #   for (t_index in 1:length(t_values)) {
    #     t <- t_values[t_index]
    #     sum_val <- mean_function(t, i, N)
    #     for (l in 0:L) {
    #       sum_val <- sum_val + sqrt(lambda (l)) * tau[i,l + 1] * phi(l, t)
    #     }
    #     Y[i, t_index] <- sum_val
    #   }
    # }
    # return(Y)
  }
  Y_simulated <- simulate_Y(N, L, rho, t_values)
  
  #1. L2 distance
  # integral_distance <- function(vec1, vec2) {
  #   f <- function(x) {
  #     # 插值找到當前x值下vec1和vec2的值
  #     y1 <- approx(1:length(vec1), vec1, x)$y
  #     y2 <- approx(1:length(vec2), vec2, x)$y
  #     (y1 - y2)^2
  #   }
  #   integral <- integrate(f, lower = 1, upper = length(vec1))
  #   sqrt(integral$value)
  # }

  #2. with derivative information
  # integral_distance <- function(vec1, vec2, t = t_values) {
  #   diff_square <- (vec1 - vec2)^2
  # 
  #   # 計算導數
  #   d_vec1 <- diff(vec1) / diff(t)
  #   d_vec2 <- diff(vec2) / diff(t)
  #   # 因為diff()會減少一個長度，所以需要對時間t作相同的處理
  #   t_diff <- t[-length(t)]
  # 
  #   # 計算導數的差值平方
  #   diff_deriv_square <- (d_vec1 - d_vec2)^2
  # 
  #   integral1 <- trapz(t, diff_square)
  #   integral2 <- trapz(t_diff, diff_deriv_square)
  # 
  #   # 平方根
  #   sqrt(integral1 + integral2)
  # }
  
  #3. General Mahalanobis distance
  # integral_distance <- function(FD1, i, j, t = t_values, eigval, eigfunc) {
  #   x <- gmfd::funData( t, FD1$data[[1]][i, ] )
  #   y <- gmfd::funData( t, FD1$data[[1]][j, ] )
  #   gmfd::funDist( x, y, metric = "mahalanobis", p = 10^5, eigval, eigfunc )
  # }

  # no_cores <- detectCores(logical = FALSE)
  # cl <- makeCluster(no_cores)
  # registerDoParallel(cl)
  # n = N
  
  # FD1 <- funData( t_values, Y_simulated )
  # eigval <- eigen( cov( FD1$data[[1]] ) )$values
  # eigfunc <- eigen( cov( FD1$data[[1]] ) )$vectors
  
  # distance_matrix <- foreach(i = 1:n, .combine='cbind', .export = "t_values", .packages = 'pracma') %dopar% {
  #   column_i <- numeric(n)
  #   for (j in 1:n) {
  #     column_i[j] <- integral_distance(Y_simulated[i, ], Y_simulated[j, ], t_values) # 
  #     # column_i[j] <- integral_distance(FD1, i, j, t_values, eigval, eigfunc)
  #   }
  #   column_i
  # }
  # distance_matrix <- matrix(0, n, n)
  # for (i in 1:n) {
  #   for (j in 1:n) {
  #     distance_matrix[i, j] <- integral_distance(Y_simulated[i, ], Y_simulated[j, ])
  #   }
  # }
  # stopCluster(cl)
  # distance_matrix <- t(distance_matrix)
  # diag(distance_matrix) = max(distance_matrix)+100
  
  return(Y_simulated)
}
# Graph
start = Sys.time()
Y_simulated = sim1(rho=0.2, mean_change=FALSE, scale=1, cov_change=TRUE)

plot(t_values, Y_simulated[1,], type = "l", ylim = c(min(Y_simulated), max(Y_simulated)), xlab = "t", ylab = "Y(t)")
for (i in 2:150) {
  lines(t_values, Y_simulated[i,], col = "black")
}
for (i in 151:N) {
  lines(t_values, Y_simulated[i,], col = "red")
}
end = Sys.time()
print(paste0("took: ", round(as.numeric(difftime(time1 = end, time2 = start, units = "secs")), 3), " seconds"))
```

# Settings

```{r}
# we can make some alternative, arl can't be derived analytically, but can be implemented well through simulation
# functional boxplot
permutationTest <- function(rank, climit, m0, nbound, minwin, maxwin, mu, sd, lambda) {
  
  num = dim(rank)[1]
  ndim = dim(rank)[2]
  sequence <- 1:num
  pRank <- matrix(0, nrow = num, ncol = ndim)
  tmpRank <- matrix(0, nrow = num, ncol = ndim)
  win <- min(max(num - m0, minwin), maxwin)
  lower <- ifelse(num - win > m0, num - win, m0)

  icount <- 0
  # Tval <- numeric(nbound)

  no_cores <- detectCores(logical = FALSE)
  cl <- makeCluster(no_cores)
  registerDoParallel(cl)
  results <- foreach(icount = 1:nbound, .combine = 'c') %dopar% { # for (icount in 1:nbound) {
    sequence <- sample(sequence)
    flag <- TRUE

    for (i in 0:(ndim-1)) {
      for (j in 0:(num-1)) {
        pRank[j+1, i+1] <- rank[sequence[j + 1], i + 1]
        tmpRank[j+1, i+1] <- pRank[j+1, i+1]
      }
    }
    for (i in 1:(num - lower - 1)) {
      pTval <- 0
      pwin <- min(max(num - m0 - i + 1, minwin), maxwin)
      # pwin <- pmin(pmax(num - m0 - i + 1, minwin), maxwin)

      for (j in 0:(ndim-1)) {
        colTval <- 0

        for (k in (lower - pwin + 1):(num - i - 1)) {
          
          if (pRank[k + 1, j + 1] > pRank[num - i + 1, j + 1]) {
            tmpRank[k + 1, j + 1] <- tmpRank[k + 1, j + 1] - 1
          }

          if (k >= num - i - pwin) {
            colTval <- (1 - lambda) * colTval + tmpRank[k + 1, j + 1] - (num - i + 1) / 2
          }
        }

        colTval <- (colTval / sd[num - m0 - i])^2
        pTval <- pTval + colTval
      }

      if (pTval >= climit[num - m0 - i]) {
        flag <- FALSE
        break
      }
    }
    if (flag) {
      # Tval[icount] = 0
      finalTval <- 0

      for (j in 0:(ndim-1)) {
        colTval <- 0
        for (k in (num - win):(num-1)) {
          colTval <- (1 - lambda) * colTval + pRank[k + 1, j + 1] - (num + 1) / 2
        }

        colTval <- (colTval / sd[num - m0])^2
        # Tval[icount] <- Tval[icount] + colTval
        finalTval <- finalTval + colTval
      }
      return(finalTval)
    } else {
      return(NA)
    }
  }
  stopCluster(cl)
  return(results)
  # return(Tval)
}

getdepth <- function(data){
  ed = extremal_depth(data)
  ld = linfinity_depth(data)
  mbd = modified_band_depth(data)
  pd = projection_depth(data)
  tvd = total_variation_depth(data)$tvd
  return(cbind(ed, ld, mbd, pd, tvd))
}

RobustDFEWMA <- function(minwin, maxwin, dim, kmax, m0, alpha, nbound, lambda, rawSample) {
  win <- pmax(minwin, 1:kmax)
  win <- pmin(win, maxwin)
  
  sampleNum <- m0 + 1:kmax
  mu <- win * (sampleNum + 1) / 2
  sd <- sqrt((win * (sampleNum + 1) * (sampleNum - win)) / 12)
  
  # Initialize some variables
  climit <- numeric(kmax)
  Tval <- numeric(kmax)
  # runlength <- kmax
  
  # Allocate and initialize the rank matrix
  rankMat <- matrix(0, nrow = kmax + m0, ncol = dim)
  
  # Sort and store the rank in the matrix
  # for (i in 1:dim) { # commented
  #   idx <- order(rawSample[1:m0, i])
  #   rankMat[idx, i] <- 1:m0
  # }

  for (i in 1:kmax) {
    cidx <- m0 + i
    # csample <- rawSample[cidx, ] # commented
    depthupdate <- getdepth(rawSample[1:cidx, ]) # added
    
    for (g in 1:dim) { # added
      idx <- order(depthupdate[1:cidx, g])
      rankMat[idx, g] <- 1:cidx
    }

    # Update the rank of the whole samples
    eidx <- 1:(cidx - 1)
    
    for (j in 1:dim) {
      largerIdx <- which(depthupdate[eidx, j] > depthupdate[cidx, j]) # which(rawSample[eidx, j] > csample[j])
      rankMat[largerIdx, j] <- rankMat[largerIdx, j] + 1
      rankMat[cidx, j] <- cidx - length(largerIdx)
    }
    
    # Compute the rank statistics
    weight <- (win[i] - 1):0
    weight <- (1 - lambda)^weight
    wm <- matrix(rep(weight, dim), nrow = length(weight), ncol = dim, byrow = TRUE)
    sub_rankMat <- rankMat[(cidx-win[i]+1):cidx, ]
    adjusted_rank <- sub_rankMat - (cidx + 1)/2
    Tval[i] <- sum(colSums(wm * adjusted_rank)^2) / (sd[i]^2)
    
    # Obtain the permutation
    permT <- numeric(nbound)
    if (i == 1) {
      for (icount in 1:nbound) {
        per <- sample(cidx)
        pRank <- rankMat[per, ]
        sub_rank <- pRank[(cidx-win[i]+1):cidx, ] - (cidx + 1)/2
        permT[icount] <- sum(colSums(wm * sub_rank)^2) / (sd[i]^2)
      }
    } else {
      permT <- permutationTest(rankMat[1:cidx, ], climit, m0, nbound, minwin, maxwin, mu, sd, lambda)
    }
    # Find the critical value of the test
    climit[i] <- quantile(permT, 1 - alpha, na.rm = TRUE)
    if (Tval[i] > climit[i]) {
      # runlength <- i
      # print(paste0("tau : ", 50 + i))
      # maxTk <- 0
      # for (j in 0:(i-1)) {
      #   weight <- ((i-j) - 1):0
      #   wm <- matrix(rep(weight, dim), nrow = length(weight), ncol = dim, byrow = TRUE)
      #   sub_rankMat <- rankMat[(cidx-(i-j)+1):cidx, ]
      #   adjusted_rank <- sub_rankMat - (cidx + 1)/2
      #   Tkval <- sum(colSums(wm * adjusted_rank)^2) / (sd[i]^2)
      #   if(Tkval > maxTk){
      #     maxTk <- Tkval
      #     loc_est <- j
      #   }
      # }
      # return(list(tau = m0 + i, loc_est = m0 + loc_est))
      return(m0 + i)
      break
    }
  }
}

########################################################################################

RobustDFEWMA <- function(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, rawSample, histm0, phi, mufunc, update) { # added histm0 & phi & mu & update
  win <- pmax(minwin, 1:kmax)
  win <- pmin(win, maxwin)
  
  sampleNum <- m0 + 1:kmax
  mu <- win * (sampleNum + 1) / 2
  sd <- sqrt((win * (sampleNum + 1) * (sampleNum - win)) / 12)
  
  # Initialize some variables
  climit <- numeric(kmax)
  Tval <- numeric(kmax)
  # runlength <- kmax
  
  # Allocate and initialize the rank matrix
  rankMat <- matrix(0, nrow = kmax + m0, ncol = dim)
  
  # Sort and store the rank in the matrix
  for (i in 1:dim) { # functional depth, simply set dim to 1
    idx <- order(histm0[1:m0, i])
    rankMat[idx, i] <- 1:m0
  }
  
  # Generate sample from the distribution, and start running MSPC
  
  histupdate <- histm0
  for (i in 1:kmax) {
    cidx <- m0 + i
    if(update == TRUE && i%%10 == 0){
      yList = lapply(1:(50+i), function(l) Y_simulated[l, ])
      tList = replicate(50+i, t_values, simplify = FALSE)
      Yfpca = FPCA(yList, tList, list(useBinnedData = 'OFF'))
      mufunc = Yfpca$mu
      phi = Yfpca$phi[, 1:dim]
    }
    newLy_centered <- rawSample[cidx, ] - mufunc
    csample <- newLy_centered%*%phi
    
    # Update the rank of the whole samples
    eidx <- 1:(cidx - 1)
    histupdate <- rbind(histupdate, csample)
    
    for (j in 1:dim) {
      largerIdx <- which(histupdate[eidx, j] > csample[j])
      rankMat[largerIdx, j] <- rankMat[largerIdx, j] + 1
      rankMat[cidx, j] <- cidx - length(largerIdx)
    }
    
    # Compute the rank statistics
    weight <- (win[i] - 1):0
    weight <- (1 - lambda)^weight
    wm <- matrix(rep(weight, dim), nrow = length(weight), ncol = dim, byrow = TRUE)
    sub_rankMat <- rankMat[(cidx-win[i]+1):cidx, ]
    adjusted_rank <- sub_rankMat - (cidx + 1)/2
    Tval[i] <- sum(colSums(wm * adjusted_rank)^2) / (sd[i]^2)
    
    # Obtain the permutation
    permT <- numeric(nbound)
    if (i == 1) {
      for (icount in 1:nbound) {
        per <- sample(cidx)
        pRank <- rankMat[per, ]
        sub_rank <- pRank[(cidx-win[i]+1):cidx, ] - (cidx + 1)/2
        permT[icount] <- sum(colSums(wm * sub_rank)^2) / (sd[i]^2)
      }
    } else {
      permT <- permutationTest(rankMat[1:cidx, ], climit, m0, nbound, minwin, maxwin, mu, sd, lambda)
    }
    # Find the critical value of the test
    climit[i] <- quantile(permT, 1 - alphaerr, na.rm = TRUE)
    if (Tval[i] > climit[i]) {
      # runlength <- i
      # print(paste0("tau : ", 50 + i))
      return(50 + i)
      break
    }
  }
}

performance150 <- function(result){
  cp <- readRDS(result)
  print(paste0("Successful: ",length(cp[which(cp>=150)])," Average delay: ",round(mean(cp[which(cp >= 150)]-150),3)," Undetected change count: ",100- length(cp)))
}

performance100 <- function(result){
  cp <- readRDS(result)
  print(paste0("Successful: ",length(cp[which(cp>=100)])," Average delay: ",round(mean(cp[which(cp >= 100)]-100),3)," Undetected change count: ",100- length(cp)))
}

minwin <- 5
maxwin <- 10
dim <- 1000 # dimension of the variable
kmax <- 125 # the maximum number in the simulation
m0 <- 75 # in control sample points
alphaerr <- 0.002 # ARL 500
nbound <- 500 # the number of permutation required
lambda <- 0.05

N = 200
Y_simulated = sim1(rho=0, mean_change=TRUE, scale=2, cov_change=FALSE)
# yList = lapply(1:50, function(i) Y_simulated[i, ])
# tList = replicate(50, t_values, simplify = FALSE)
# Yfpca = FPCA(yList, tList, list(useBinnedData = 'OFF'))
# # plot(Yfpca)
# mufunc = Yfpca$mu
# FPCs = which(Yfpca$cumFVE > 0.9)[1]
# histm0 = Yfpca$xiEst[, 1:FPCs]
# dim = dim(histm0)[2]
# phi = Yfpca$phi[, 1:FPCs]

dim = 5
RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated)
# RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated, histm0, phi, mufunc)
```

# Verify ARLs

```{r}
start.time <- Sys.time()
dim <- 1000; alphaerr <- 0.002; lambda = 0.05
kmax <- 700 # the maximum number in the simulation
m0 <- 75 # in control sample points
cl <- makeCluster(detectCores(logical = FALSE))
registerDoParallel(cl)

change_points <- foreach(i = 1:50, .packages = c("doParallel", "fdaoutlier")) %dopar% {
  N = 700
  Y_simulated <- sim1(rho = 0.2, mean_change = FALSE, scale = 1, cov_change = FALSE)$Y_simulated
  RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated)
}

stopCluster(cl)
change_points <- unlist(compact(change_points))
mean(change_points)
saveRDS(change_points, "control_chart_no_change_500arl.rds")
end.time <- Sys.time()
print(end.time - start.time)
```

# fdapace example

```{r}
M <- 200 #number of measurements per subjects
N <- 100 # the number of subjects
set.seed(123) #for bootstrap
##### DEFINE ####
s <- seq(0,10,length.out = M) #from 0 to 10, time length 200(=M)
# generating functions
meanFunct <- function(s) s+10*exp(-(s-5)^2)
eigFunct1 <- function(s) cos(2*s*pi/10)/sqrt(5)
eigFunct2 <- function(s) sin(2*s*pi/10)/sqrt(5)
plot(s,meanFunct(s),type='l')
plot(s,eigFunct1(s),type='l',col='red')
plot(s,eigFunct2(s),type='l',col='blue')
Ksi <- matrix(rnorm(N*2),ncol=2) # Random residuals for eigen effects
Ksi <- apply(Ksi,2,scale) # Centering of matrix
Ksi <- Ksi %*% diag(c(5,2))
yTrue <- Ksi %*% t(matrix(c(eigFunct1(s),eigFunct2(s)),ncol=2)) + t(matrix(rep(meanFunct(s),N),nrow=M))
dim(yTrue)
plot(s, yTrue[1,], type = "l", ylim = c(min(yTrue), max(yTrue)), xlab = "t", ylab = "Y(t)")
for (i in 2:N) {
  lines(s, yTrue[i,], col = "black")
}
L3 <- MakeFPCAInputs(
  IDs = rep(1:N, each=M),
  tVec = rep(s,N),
  t(yTrue)
)
yList = lapply(1:N, function(i) yTrue[i, ])
tList = replicate(N, s, simplify = FALSE)r
FPCAdense <- FPCA(L3$Ly, L3$Lt)
plot(FPCAdense)
FPCAdense <- FPCA(yList, tList)
plot(FPCAdense)
```

# Mean change

```{r}
# average time lag?
start.time <- Sys.time()
count = 0; N = 200; kmax = 125; m0 = 75; alphaerr <- 0.002; cp <- c() # N = 150; kmax = 75; alphaerr
cl <- makeCluster(detectCores(logical = FALSE)-1)
registerDoParallel(cl)

results <- foreach(i = 1:100, .packages = c("doParallel", "fdaoutlier")) %dopar% {
  Y_simulated <- sim1(rho = 0, mean_change = TRUE, scale = 1, cov_change = FALSE) # rho = 0.2
  dim = 5
  # dim = 1000
  change_points <- RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated)
  
  if (is.null(change_points)) {
    list(count = 0, cp = NULL)
  } else if (change_points >= 150) { # 100
    list(count = 1, cp = change_points)
  } else {
    list(count = 0, cp = change_points)
  }
}
stopCluster(cl)
for (result in results) {
  count <- count + result$count
  cp <- c(cp, result$cp)
}

# for(i in 1:100){
#   print(paste0("Run: ", i))
#   Y_simulated = sim1(rho=0.2, mean_change=TRUE, scale=1, cov_change=FALSE)$Y_simulated
  
  # yList = lapply(1:50, function(i) Y_simulated[i, ])
  # tList = replicate(50, t_values, simplify = FALSE)
  # Yfpca = FPCA(yList, tList, list(useBinnedData = 'OFF'))
  # mufunc = Yfpca$mu
  # FPCs = which(Yfpca$cumFVE > 0.9)[1]
  # histm0 = Yfpca$xiEst[, 1:FPCs]
  # dim = dim(histm0)[2]
  # phi = Yfpca$phi[, 1:FPCs]
  # change_points <- RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated, histm0, phi, mufunc, TRUE)
  
  # change_points <- RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated)
  # cp <- c(cp, change_points)

  # if(!is.null(change_points) && change_points >= 75 && change_points <= 90){
  #   count = count + 1
  # }

#   if (is.null(change_points)) {
#     edgefail <- edgefail + 1
#   }else if (change_points >= 150) {
#     count <- count + 1
#   }
# }
print(paste0("Successful detection count: ", count))
saveRDS(cp, "control_chart_mean_change_500arl_depth_cp150.rds")
end.time <- Sys.time()
print(end.time - start.time)

# limitation: time points should be identical
# cp <- readRDS("control_chart_mean_change_500arl.rds") # 2.704884 hours
# print(paste0("Successful detection count: ", length(cp[which(cp >= 75 & cp <= 90)])))
# print(paste0("Average delay: ", mean(cp[which(cp >= 75)]-75)))

# setwd("C:/Users/dakin/Desktop/Online CPD/multivariate data online CPD/control chart/rho0.2")
performance150("control_chart_mean_change_500arl_cp150.rds") # 2.874206 hours 2.859436 hours
performance150("control_chart_mean_change_1000arl_cp150.rds") # 2.789155 hours 3.411252 hours
performance150("control_chart_mean_change_1500arl_cp150.rds") # 2.335471 hours 3.343081 hours
performance100("control_chart_mean_change_500arl_cp100.rds") # 55.08026 mins 1.185658 hours
performance100("control_chart_mean_change_1000arl_cp100.rds") # 1.021969 hours 1.198062 hours
performance100("control_chart_mean_change_1500arl_cp100.rds") # 1.098476 hours 1.275404 hours
print("--------------------------------")
performance150("control_chart_mean_change_500arl_depth_cp150.rds") # 29.47108 mins 26.87564 mins
performance150("control_chart_mean_change_1000arl_depth_cp150.rds") # 30.06588 mins
performance150("control_chart_mean_change_1500arl_depth_cp150.rds") # 31.21382 mins
performance100("control_chart_mean_change_500arl_depth_cp100.rds") # 14.42202 mins
performance100("control_chart_mean_change_1000arl_depth_cp100.rds") # 16.31776 mins
performance100("control_chart_mean_change_1500arl_depth_cp100.rds") # 14.64207 mins
```

# Scale change

```{r}
start.time <- Sys.time()
count = 0; N = 200; kmax = 125; m0 = 75; alphaerr <- 0.002; cp <- c() # N = 150; kmax = 75; alphaerr
cl <- makeCluster(detectCores(logical = FALSE))
registerDoParallel(cl)

results <- foreach(i = 1:100, .packages = c("doParallel", "fdaoutlier")) %dopar% {
  Y_simulated <- sim1(rho = 0, mean_change = FALSE, scale = 2, cov_change = FALSE) # rho = 0.2
  dim = 5
  # dim = 1000
  change_points <- RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated)
  
  if (is.null(change_points)) {
    list(count = 0, cp = NULL)
  } else if (change_points >= 150) { # 100
    list(count = 1, cp = change_points)
  } else {
    list(count = 0, cp = change_points)
  }
}
stopCluster(cl)
for (result in results) {
  count <- count + result$count
  cp <- c(cp, result$cp)
}

# for(i in 1:100){
#   print(paste0("Run: ", i))
#   Y_simulated = sim1(rho=0.2, mean_change=FALSE, scale=2, cov_change=FALSE)$Y_simulated
  
  # yList = lapply(1:50, function(i) Y_simulated[i, ])
  # tList = replicate(50, t_values, simplify = FALSE)
  # Yfpca = FPCA(yList, tList, list(useBinnedData = 'OFF'))
  # mufunc = Yfpca$mu
  # FPCs = which(Yfpca$cumFVE > 0.9)[1]
  # histm0 = Yfpca$xiEst[, 1:FPCs]
  # dim = dim(histm0)[2]
  # phi = Yfpca$phi[, 1:FPCs]
  # change_points <- RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated, histm0, phi, mufunc, TRUE)
  
  # change_points <- RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated)
  # cp <- c(cp, change_points)

  # if(!is.null(change_points) && change_points >= 75 && change_points <= 90){
  #   count = count + 1
  # }

#   if (is.null(change_points)) {
#     edgefail <- edgefail + 1
#   }else if (change_points >= 150) {
#     count <- count + 1
#   }
# }
print(paste0("Successful detection count: ", count))
saveRDS(cp, "control_chart_scale_change_500arl_depth_cp150.rds")
end.time <- Sys.time()
print(end.time - start.time)

# cp <- readRDS("control_chart_scale_change_500arl.rds") # 3.672959 hours
# print(paste0("Successful detection count: ", length(cp[which(cp >= 75 & cp <= 90)])))
# print(paste0("Average delay: ", mean(cp[which(cp >= 75)]-75)))

# setwd("C:/Users/dakin/Desktop/Online CPD/multivariate data online CPD/control chart/rho0.2")
performance150("control_chart_scale_change_500arl_cp150.rds") # 3.196204 hours 3.928592 hours
performance150("control_chart_scale_change_1000arl_cp150.rds") # 3.559229 hours 4.555999 hours
performance150("control_chart_scale_change_1500arl_cp150.rds") # 2.929162 hours 4.238188 hours
performance100("control_chart_scale_change_500arl_cp100.rds") # 1.353127 hours 2.181065 hours
performance100("control_chart_scale_change_1000arl_cp100.rds") # 1.643093 hours 2.398013 hours
performance100("control_chart_scale_change_1500arl_cp100.rds") # 1.642153 hours 2.55826 hours
print("--------------------------------")
performance150("control_chart_scale_change_500arl_depth_cp150.rds") # 29.19687 mins 27.52374 mins
performance150("control_chart_scale_change_1000arl_depth_cp150.rds") # 30.63652 mins
performance150("control_chart_scale_change_1500arl_depth_cp150.rds") # 32.8126 mins
performance100("control_chart_scale_change_500arl_depth_cp100.rds") # 14.18259 mins
performance100("control_chart_scale_change_1000arl_depth_cp100.rds") # 13.07578 mins
performance100("control_chart_scale_change_1500arl_depth_cp100.rds") # 12.86341 mins
```

# Mean + Scale change

```{r}
start.time <- Sys.time()
count = 0; N = 200; kmax = 125; m0 = 75; alphaerr <- 0.002; cp <- c() # N = 150; kmax = 75; alphaerr
cl <- makeCluster(detectCores(logical = FALSE))
registerDoParallel(cl)

results <- foreach(i = 1:100, .packages = c("doParallel", "fdaoutlier")) %dopar% {
  Y_simulated <- sim1(rho = 0, mean_change = TRUE, scale = 2, cov_change = FALSE) # rho = 0.2
  dim = 5
  # dim = 1000
  change_points <- RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated)
  
  if (is.null(change_points)) {
    list(count = 0, cp = NULL)
  } else if (change_points >= 150) { # 100
    list(count = 1, cp = change_points)
  } else {
    list(count = 0, cp = change_points)
  }
}
stopCluster(cl)
for (result in results) {
  count <- count + result$count
  cp <- c(cp, result$cp)
}

# for(i in 1:100){
#   print(paste0("Run: ", i))
#   Y_simulated = sim1(rho=0.2, mean_change=TRUE, scale=2, cov_change=FALSE)$Y_simulated
  
  # yList = lapply(1:50, function(i) Y_simulated[i, ])
  # tList = replicate(50, t_values, simplify = FALSE)
  # Yfpca = FPCA(yList, tList, list(useBinnedData = 'OFF'))
  # mufunc = Yfpca$mu
  # FPCs = which(Yfpca$cumFVE > 0.9)[1]
  # histm0 = Yfpca$xiEst[, 1:FPCs]
  # dim = dim(histm0)[2]
  # phi = Yfpca$phi[, 1:FPCs]
  # change_points <- RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated, histm0, phi, mufunc, TRUE)
  
  # change_points <- RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated)
  # cp <- c(cp, change_points)

  # if(!is.null(change_points) && change_points >= 75 && change_points <= 90){
  #   count = count + 1
  # }

#   if (is.null(change_points)) {
#     edgefail <- edgefail + 1
#   }else if (change_points >= 150) {
#     count <- count + 1
#   }
# }
print(paste0("Successful detection count: ", count))
saveRDS(cp, "control_chart_mean_scale_change_500arl_depth_cp150.rds")
end.time <- Sys.time()
print(end.time - start.time)

# cp <- readRDS("control_chart_mean_scale_change_500arl.rds") # 3.288997 hours
# print(paste0("Successful detection count: ", length(cp[which(cp >= 75 & cp <= 90)])))
# print(paste0("Average delay: ", mean(cp[which(cp >= 75)]-75)))

# setwd("C:/Users/dakin/Desktop/Online CPD/multivariate data online CPD/control chart/rho0.2")
performance150("control_chart_mean_scale_change_500arl_cp150.rds") # 2.559818 hours 3.444347 hours
performance150("control_chart_mean_scale_change_1000arl_cp150.rds") # 2.877327 hours 3.46972 hours
performance150("control_chart_mean_scale_change_1500arl_cp150.rds") # 2.310067 hours 3.724514 hours
performance100("control_chart_mean_scale_change_500arl_cp100.rds") # 1.18248 hours 1.468244 hours
performance100("control_chart_mean_scale_change_1000arl_cp100.rds") # 1.219216 hours 1.63003 hours
performance100("control_chart_mean_scale_change_1500arl_cp100.rds") # 1.17994 hours 1.768397 hours
print("--------------------------------")
performance150("control_chart_mean_scale_change_500arl_depth_cp150.rds") # 29.94013 mins
performance150("control_chart_mean_scale_change_1000arl_depth_cp150.rds") # 30.71265 mins
performance150("control_chart_mean_scale_change_1500arl_depth_cp150.rds") # 32.06022 mins
performance100("control_chart_mean_scale_change_500arl_depth_cp100.rds") # 13.24262 mins
performance100("control_chart_mean_scale_change_1000arl_depth_cp100.rds") # 12.72974 mins
performance100("control_chart_mean_scale_change_1500arl_depth_cp100.rds") # 12.6438 mins
```

# Covariance structure change

```{r}
start.time <- Sys.time()
count = 0; N = 200; kmax = 125; m0 = 75; alphaerr <- 0.002; cp <- c() # N = 150; kmax = 75; alphaerr
cl <- makeCluster(detectCores(logical = FALSE))
registerDoParallel(cl)

results <- foreach(i = 1:100, .packages = c("doParallel", "fdaoutlier")) %dopar% {
  Y_simulated <- sim1(rho = 0, mean_change = FALSE, scale = 1, cov_change = TRUE) # rho = 0.2
  dim = 5
  # dim = 1000
  change_points <- RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated)
  
  if (is.null(change_points)) {
    list(count = 0, cp = NULL)
  } else if (change_points >= 150) { # 100
    list(count = 1, cp = change_points)
  } else {
    list(count = 0, cp = change_points)
  }
}
stopCluster(cl)
for (result in results) {
  count <- count + result$count
  cp <- c(cp, result$cp)
}

# for(i in 1:100){
#   print(paste0("Run: ", i))
#   Y_simulated = sim1(rho=0.2, mean_change=FALSE, scale=1, cov_change=TRUE)$Y_simulated
  
  # yList = lapply(1:50, function(i) Y_simulated[i, ])
  # tList = replicate(50, t_values, simplify = FALSE)
  # Yfpca = FPCA(yList, tList, list(useBinnedData = 'OFF'))
  # mufunc = Yfpca$mu
  # FPCs = which(Yfpca$cumFVE > 0.9)[1]
  # histm0 = Yfpca$xiEst[, 1:FPCs]
  # dim = dim(histm0)[2]
  # phi = Yfpca$phi[, 1:FPCs]
  # change_points <- RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated, histm0, phi, mufunc, TRUE)
  
  # change_points <- RobustDFEWMA(minwin, maxwin, dim, kmax, m0, alphaerr, nbound, lambda, Y_simulated)
  # cp <- c(cp, change_points)

  # if(!is.null(change_points) && change_points >= 75 && change_points <= 90){
  #   count = count + 1
  # }

#   if (is.null(change_points)) {
#     edgefail <- edgefail + 1
#   }else if (change_points >= 150) {
#     count <- count + 1
#   }
# }
print(paste0("Successful detection count: ", count))
saveRDS(cp, "control_chart_cov_change_500arl_depth_cp150.rds")
end.time <- Sys.time()
print(end.time - start.time)

# cp <- readRDS("control_chart_cov_change_500arl.rds") # 2.959011 hours
# print(paste0("Successful detection count: ", length(cp[which(cp >= 75 & cp <= 90)])))
# print(paste0("Average delay: ", mean(cp[which(cp >= 75)]-75)))

# setwd("C:/Users/dakin/Desktop/Online CPD/multivariate data online CPD/control chart/rho0.2")
performance150("control_chart_cov_change_500arl_cp150.rds") # 2.591402 hours 3.057422 hours
performance150("control_chart_cov_change_1000arl_cp150.rds") # 3.179484 hours 3.240268 hours
performance150("control_chart_cov_change_1500arl_cp150.rds") # 2.469478 hours 3.332654 hours
performance100("control_chart_cov_change_500arl_cp100.rds") # 52.61243 mins 1.043083 hours
performance100("control_chart_cov_change_1000arl_cp100.rds") # 56.61729 mins 1.112452 hours
performance100("control_chart_cov_change_1500arl_cp100.rds") # 59.55676 mins 1.135372 hours
print("--------------------------------")
performance150("control_chart_cov_change_500arl_depth_cp150.rds") # 33.53687 mins
performance150("control_chart_cov_change_1000arl_depth_cp150.rds") # 32.77533 mins
performance150("control_chart_cov_change_1500arl_depth_cp150.rds") # 37.12778 mins
performance100("control_chart_cov_change_500arl_depth_cp100.rds") # 17.49853 mins
performance100("control_chart_cov_change_1000arl_depth_cp100.rds") # 18.70818 mins
performance100("control_chart_cov_change_1500arl_depth_cp100.rds") # 21.86838 mins
```
